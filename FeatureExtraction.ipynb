{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0c3a87d47df41f4974eddd44c30377a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(VBox(children=(Label(value='Emotions'),)), SelectMultiple(index=(0,), layout=Layâ€¦"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "from IPython.display import display\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import src.FeatureExplorer.DataController as datacontrol\n",
    "import src.FeatureExplorer.ViewController as vc\n",
    "\n",
    "df = datacontrol.dataframe('datasets/RAVDESS/metadata/RAVDESS.csv')\n",
    "vc.view_feature_controls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import recall_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class GridCV:\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.features_train = df.features_train\n",
    "        self.label_train = df.labels_train\n",
    "\n",
    "\n",
    "    def perform_gridsearch(self):\n",
    "        param_grid={\n",
    "            \"C\" : [0.1,0.5,0.8,1.0,1.2,1.5,2],\n",
    "            \"gamma\" : [\"auto\",\"scale\"],\n",
    "            \"class_weight\" : [\"balanced\",None]\n",
    "        }\n",
    "\n",
    "\n",
    "        from time import time\n",
    "        cv = GroupKFold(5)\n",
    "        rng = np.random.RandomState(7)\n",
    "        groups = rng.randint(0, 10, size=len(self.label_train))\n",
    "        grid_search = GridSearchCV(SVC(kernel='rbf'), param_grid=param_grid,scoring='recall',cv=cv,return_train_score=True)\n",
    "        start = time()\n",
    "        grid_search.fit(self.features_train, self.label_train, groups=groups)\n",
    "\n",
    "        print(\n",
    "            \"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "            % (time() - start, len(grid_search.cv_results_[\"params\"]))\n",
    "        )\n",
    "        use_cols = ['param_C','param_class_weight',  'param_gamma', 'mean_test_score','mean_train_score','std_test_score', 'rank_test_score']\n",
    "        gr = pd.DataFrame(grid_search.cv_results_)[use_cols]\n",
    "        gr.sort_values(by='rank_test_score',inplace=True)\n",
    "        return gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record Visualizers, add to module when done\n",
    "from sklearn.metrics import ConfusionMatrixDisplay,RocCurveDisplay,PrecisionRecallDisplay,DetCurveDisplay\n",
    "class ViewGridSearchResults:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.fig  = plt.figure(figsize=(3,3))\n",
    "\n",
    "    def print_records_to_table(self, records):\n",
    "        \n",
    "        self.fig.clf()\n",
    "        \n",
    "        cols = records[0]\n",
    "        cell_text = records[1]\n",
    "\n",
    "        ax = self.fig.subplots()\n",
    "        self.fig.suptitle(\"Top Grid Search Results\")\n",
    "        \n",
    "        self.fig.patch.set_visible(False)\n",
    "        ax.axis('off')\n",
    "        ax.axis('tight')\n",
    "        self.fig.tight_layout()\n",
    "        self.fig.canvas.header_visible = False\n",
    "        \n",
    "        col_widths = [0.15,0.16,0.17,0.16,0.18,0.18]\n",
    "\n",
    "        table = ax.table(cellText=cell_text,colLabels=cols,loc='center',colWidths=col_widths)\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(8)\n",
    "        table.scale(1.5,1.5)\n",
    "       \n",
    "        return self.fig\n",
    "\n",
    "\n",
    "class ViewPrecisionRecall:\n",
    "    \n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.fig = plt.figure(figsize=(4,3))\n",
    "       \n",
    "        \n",
    "    def show_precision_recall(self,train_model,features_train,features_test,labels_train,labels_test,test_model,test_mode):\n",
    "        self.fig.clf()\n",
    "        \n",
    "        ax = self.fig.subplots()\n",
    "        #self.fig.set_size_inches(4,3)\n",
    "        self.fig.canvas.header_visible = False\n",
    "        ax.set_title(\"Precision Recall Curve (PRC)\")\n",
    "        PrecisionRecallDisplay.from_estimator(train_model, features_train, labels_train,ax=ax,name='train',plot_chance_level=True) \n",
    "        \n",
    "        if test_mode == 1:\n",
    "            pred = test_model.decision_function(features_test)\n",
    "            PrecisionRecallDisplay.from_predictions(labels_test,pred,ax=ax,name=\"test\",plot_chance_level=True)\n",
    "        ax.set_aspect('auto')\n",
    "        #ax.set_box_aspect(0.7)\n",
    "        ax.set_ylabel('Precision')\n",
    "        ax.set_xlabel('Recall')\n",
    "        ax.legend(bbox_to_anchor=(0.1, -0.1), loc='upper left', borderaxespad=0)\n",
    "\n",
    "\n",
    "        self.fig.tight_layout()\n",
    "        return self.fig\n",
    "\n",
    "\n",
    "\n",
    "class ViewConfusionMatrix:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.train_fig = plt.figure(figsize=(3,3))\n",
    "        self.test_fig = plt.figure(figsize=(3,3))\n",
    "\n",
    "    def show_confusion_matrix_train(self,model,features_train,labels_train):\n",
    "        \n",
    "        self.train_fig.clf()\n",
    "        \n",
    "        axs = self.train_fig.subplots()\n",
    "        axs.set_title(\"Confusion Matrix Train\")\n",
    "        ConfusionMatrixDisplay.from_estimator(model, features_train, labels_train,ax=axs,colorbar=False)\n",
    "       \n",
    "        return self.train_fig\n",
    "    \n",
    "    def show_confusion_matrix_test(self,test_mode, labels_test,predictions):\n",
    "        self.test_fig.clf()\n",
    "        axs = self.test_fig.subplots()\n",
    "        axs.set_title(\"Confusion Matrix Test\")\n",
    "        if test_mode == 1:\n",
    "            ConfusionMatrixDisplay.from_predictions(labels_test,predictions,ax=axs,colorbar=False,cmap=\"magma\")\n",
    "      \n",
    "        return self.test_fig\n",
    "\n",
    "\n",
    "class ViewModelMetrics:\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        self.fig = plt.figure(figsize=(2,1.25))\n",
    "\n",
    "    def show_train_metrics(self,train_record):\n",
    "        \n",
    "        self.fig.clf()\n",
    "\n",
    "        cols = train_record[0]\n",
    "        cell_text = train_record[1]\n",
    "\n",
    "       \n",
    "        rows = [\"Train Results\"]\n",
    "        axs = self.fig.subplots()\n",
    "        self.fig.suptitle(\"Model Performance\")\n",
    "        self.fig.canvas.header_visible = False\n",
    "        self.fig.patch.set_visible(False)\n",
    "        axs.axis('off')\n",
    "        axs.axis('tight')\n",
    "        \n",
    "        table = axs.table( colLabels=cols,rowLabels=rows,cellText=[cell_text],loc='center')\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(8)\n",
    "        table.scale(1.5,1.5)\n",
    "       \n",
    "        return self.fig\n",
    "\n",
    "    def show_test_metrics(self,train_record, test_record):\n",
    "      \n",
    "        self.fig.clf()\n",
    "\n",
    "        cols = train_record[0]\n",
    "        train_row = train_record[1]\n",
    "        test_row = test_record[1]\n",
    "        \n",
    "        rows = [\"Training\",\"Testing\"]\n",
    "        axs = self.fig.subplots()\n",
    "        self.fig.suptitle(\"Model Performance\")\n",
    "        self.fig.canvas.header_visible = False\n",
    "        self.fig.patch.set_visible(False)\n",
    "        axs.axis('off')\n",
    "        axs.axis('tight')\n",
    "        \n",
    "        table = axs.table( colLabels=cols,rowLabels=rows,cellText=[train_row, test_row],loc='center')\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(8)\n",
    "        table.scale(1.5,1.5)\n",
    "     \n",
    "        return self.fig\n",
    "\n",
    "class ViewROC:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "\n",
    "    def show_ROC(self,train_model,features_train,features_test,labels_train,labels_test,test_model,test_mode):\n",
    "\n",
    "        self.fig.clf()\n",
    "        ax = self.fig.subplots()\n",
    "        ax.set_title(\"ROC Curve\")\n",
    "        RocCurveDisplay.from_estimator(train_model, features_train, labels_train,ax=ax,name=\"train\") \n",
    "        \n",
    "        if test_mode == 1:\n",
    "            pred = test_model.decision_function(features_test)\n",
    "            RocCurveDisplay.from_predictions(labels_test,pred,ax=ax,name=\"test\")\n",
    "        \n",
    "        self.fig.canvas.header_visible = False\n",
    "        ax.set_ylabel('True Positive Rate')\n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "        self.fig.tight_layout()\n",
    "        return self.fig\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ViewDET:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.fig = plt.figure(figsize=(4,3), layout=\"constrained\")\n",
    "\n",
    "    def show_DET(self,train_model,features_train,features_test,labels_train,labels_test,test_model,test_mode):\n",
    "        self.fig.clf()\n",
    "        ax = self.fig.subplots()\n",
    "        ax.set_title(\"DET Curve\")\n",
    "        self.fig.canvas.header_visible = False\n",
    "        DetCurveDisplay.from_estimator(train_model, features_train, labels_train,ax=ax,name='train')\n",
    "        if test_mode == 1:\n",
    "            pred = test_model.decision_function(features_test)\n",
    "            DetCurveDisplay.from_predictions(labels_test,pred,ax=ax,name='test')\n",
    "      \n",
    "        ax.set_ylabel('False Negative Rate')\n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "        self.fig.tight_layout()\n",
    "        return self.fig\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results Viewer\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score,precision_score,accuracy_score,d2_absolute_error_score\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class ResultsViewer:\n",
    "\n",
    "    def __init__(self, df, features_train, labels_train,features_test, labels_test):\n",
    "        \n",
    "        self.df = self.arrange_columns(df)\n",
    "        \n",
    "        self.model = SVC()\n",
    "        self.current_record_idx = 0\n",
    "\n",
    "        self.features = features_train\n",
    "        self.labels = labels_train\n",
    "\n",
    "        self.features_train = features_train\n",
    "        self.labels_train = labels_train\n",
    "\n",
    "        # Visualizers\n",
    "        self.vgr = ViewGridSearchResults()\n",
    "        self.prc = ViewPrecisionRecall()\n",
    "        self.vcm = ViewConfusionMatrix()\n",
    "        self.vmm = ViewModelMetrics()\n",
    "        self.vroc = ViewROC()\n",
    "        self.vdet = ViewDET()\n",
    "\n",
    "\n",
    "        # Testing only\n",
    "        self.features_test = features_test\n",
    "        self.labels_test = labels_test\n",
    "        self.test_model = None\n",
    "        self.test_mode = 0\n",
    "\n",
    "        self.predictions = []\n",
    "\n",
    "\n",
    "    def arrange_columns(self, in_df):\n",
    "        df = in_df.copy()\n",
    "        df['rank']=list(range(1,len(df)+1))\n",
    "        df.drop(columns=['rank_test_score'],inplace=True)\n",
    "        df.columns=['L2Mult','weight','gamma','test_recall','train_recall', 'test_stdev','rank']\n",
    "        df = df[['rank','L2Mult','weight','gamma','test_recall','train_recall', 'test_stdev']]\n",
    "        return df\n",
    "    \n",
    "\n",
    "    def get_top_records(self, num_records=10):\n",
    "        return self.df.iloc[0:num_records]\n",
    "\n",
    "    def format_top_records_table(self, recs,num_records=10):\n",
    "\n",
    "        cols = ['rank', 'weight','gamma','L2Mult','test recall', 'train recall']\n",
    "\n",
    "        cell_text = []\n",
    "        for i in range(num_records):\n",
    "            \n",
    "            weight = 'bal'\n",
    "            if recs['weight'].iloc[i] == None:\n",
    "                weight =\"unbal\"\n",
    "            \n",
    "            cell_text.append([recs['rank'].iloc[i], \n",
    "                              weight,\n",
    "                              recs['gamma'].iloc[i],\n",
    "                              round(recs['L2Mult'].iloc[i],7),\n",
    "                              round(recs['test_recall'].iloc[i],2),\n",
    "                              round(recs['train_recall'].iloc[i],2)])\n",
    "        return cols, cell_text\n",
    "\n",
    "    def print_records_to_table(self):\n",
    "        return self.vgr.print_records_to_table(self.format_top_records_table(self.get_top_records()))\n",
    "\n",
    "  ####################################################################################\n",
    "    \n",
    "    def select_record(self,idx):\n",
    "        plt.close()\n",
    "        self.current_record_idx = idx\n",
    "        self.fit_model_with_record(idx)\n",
    "\n",
    "    \n",
    "    def apply_record_to_model(self, rec_index=0):\n",
    "        \n",
    "        return SVC(C=self.df['L2Mult'].iloc[rec_index],\n",
    "                   kernel='rbf',\n",
    "                   gamma=self.df['gamma'].iloc[rec_index],\n",
    "                   class_weight=self.df['weight'].iloc[rec_index]\n",
    "                   )\n",
    "     \n",
    "           \n",
    "    def fit_model_with_record(self, rec_index=0):    \n",
    "        self.model = self.apply_record_to_model(rec_index=rec_index)\n",
    "        self.model = self.model.fit(self.features,self.labels)\n",
    "        return self.model\n",
    "       \n",
    "\n",
    "    def set_testing_model(self):\n",
    "        self.test_model = self.model\n",
    "        self.test_mode = 1\n",
    "        self.predictions = self.test_model.predict(self.features_test)\n",
    "\n",
    "\n",
    "    def show_confusion_matrix_train(self):\n",
    "        return self.vcm.show_confusion_matrix_train(self.model,\n",
    "                                                    self.features_train,\n",
    "                                                    self.labels_train)\n",
    "   \n",
    "\n",
    "    def show_confusion_matrix_test(self):\n",
    "        return self.vcm.show_confusion_matrix_test(self.test_mode,\n",
    "                                                   self.labels_test,\n",
    "                                                   self.predictions)\n",
    "    \n",
    "    def show_ROC(self):\n",
    "        return self.vroc.show_ROC(self.model,\n",
    "                                self.features_train,\n",
    "                                self.features_test,\n",
    "                                self.labels_train,\n",
    "                                self.labels_test,\n",
    "                                self.test_model,\n",
    "                                self.test_mode)\n",
    "        \n",
    "      \n",
    "    def show_DET(self):\n",
    "        return self.vdet.show_DET(self.model,\n",
    "                                self.features_train,\n",
    "                                self.features_test,\n",
    "                                self.labels_train,\n",
    "                                self.labels_test,\n",
    "                                self.test_model,\n",
    "                                self.test_mode)\n",
    "\n",
    "\n",
    "    def show_precision_recall(self):\n",
    "        return self.prc.show_precision_recall(self.model,\n",
    "                                              self.features_train,\n",
    "                                              self.features_test,\n",
    "                                              self.labels_train,\n",
    "                                              self.labels_test,\n",
    "                                              self.test_model,\n",
    "                                              self.test_mode)\n",
    "\n",
    "    def get_train_metrics(self):\n",
    "      \n",
    "        scoring = ['recall','precision','accuracy','d2_absolute_error_score']\n",
    "        scores = cross_validate(self.model, self.features, self.labels,scoring=scoring)\n",
    "        \n",
    "        cols = ['recall','precision','accuracy','d2_error']\n",
    "        cells = []\n",
    "        cells.append(round(scores['test_recall'].mean(),2))\n",
    "        cells.append(round(scores['test_precision'].mean(),2))\n",
    "        cells.append(round(scores['test_accuracy'].mean(),2))\n",
    "        cells.append(round(scores['test_d2_absolute_error_score'].mean(),2))\n",
    "\n",
    "        return cols, cells\n",
    "\n",
    "\n",
    "    def get_test_metrics(self):\n",
    "        pred = self.test_model.decision_function(self.features_test)\n",
    "        cols = ['recall','recall_micro','precision','d2_error']\n",
    "        cells = []\n",
    "        cells.append(round(recall_score(self.labels_test, self.predictions),3))\n",
    "        cells.append(round(precision_score(self.labels_test, self.predictions),3))\n",
    "        cells.append(round(accuracy_score(self.labels_test, self.predictions),3))\n",
    "        cells.append(round(d2_absolute_error_score(self.labels_test,self.predictions),3))\n",
    "        \n",
    "        return cols, cells\n",
    "    \n",
    "    def show_train_metrics(self):\n",
    "        return self.vmm.show_train_metrics(self.get_train_metrics())\n",
    "\n",
    "\n",
    "    def show_test_metrics(self):\n",
    "        return self.vmm.show_test_metrics(self.get_train_metrics(),self.get_test_metrics())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval view controller\n",
    "def eval_controller(tr):\n",
    "\n",
    "    center_align = widgets.Layout(display='flex',\n",
    "                    flex_flow='column',\n",
    "                    align_items='center',\n",
    "                    width='90%')\n",
    "\n",
    "    \n",
    "\n",
    "    rec_sel_label = widgets.Label(value=\"Select Record to View\")\n",
    "\n",
    "    rec_sel_dropdown = widgets.Dropdown(\n",
    "        options=['1','2','3','4','5','6','7','8','9','10'],\n",
    "        value='1',\n",
    "        description='',\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "\n",
    "    # Handlers\n",
    "    params_out = widgets.Output()\n",
    "    record_out = widgets.Output()\n",
    "    roc_out = widgets.Output()\n",
    "    det_out = widgets.Output()\n",
    "    stats_out =  widgets.Output()\n",
    "    cm_out = widgets.Output(layout=center_align)\n",
    "    cm2_out = widgets.Output(layout=center_align)\n",
    "    prec_recall_out = widgets.Output(layout=center_align)\n",
    "    test_metrics_out = widgets.Output()\n",
    "\n",
    "    run_oos_button  = widgets.Button(description='Test model on out of sample data',layout=center_align)\n",
    "\n",
    "    record_box = widgets.VBox([rec_sel_label,rec_sel_dropdown,record_out,prec_recall_out,run_oos_button])\n",
    "\n",
    "   \n",
    "    stat_box = widgets.VBox([stats_out,cm_out,cm2_out])\n",
    "    chart_box = widgets.VBox([roc_out, det_out])\n",
    "    left_box = record_box\n",
    "\n",
    "\n",
    "    def initialize():\n",
    "        tr.fit_model_with_record(0)\n",
    "\n",
    "        with record_out:\n",
    "\n",
    "            record_out.clear_output(wait=True)\n",
    "            display(tr.print_records_to_table())\n",
    "\n",
    "        with stats_out:\n",
    "            stats_out.clear_output(wait=True)\n",
    "            display(tr.show_train_metrics())\n",
    "\n",
    "        with cm2_out:\n",
    "            cm2_out.clear_output(wait=True)\n",
    "\n",
    "        with cm_out:\n",
    "            cm_out.clear_output(wait=True)\n",
    "            display(tr.show_confusion_matrix_train())\n",
    "\n",
    "        with roc_out:\n",
    "            roc_out.clear_output(wait=True)\n",
    "            display(tr.show_ROC())\n",
    "\n",
    "        with det_out:\n",
    "            det_out.clear_output(wait=True)\n",
    "            display(tr.show_DET())\n",
    "        \n",
    "        \n",
    "\n",
    "        with prec_recall_out:\n",
    "            prec_recall_out.clear_output(wait=True)\n",
    "            display(tr.show_precision_recall())\n",
    "\n",
    "    def select_record_to_view(dfx,names):\n",
    "        #left_box = record_box\n",
    "        val = int(names.new) - 1\n",
    "        dfx.select_record(val)\n",
    "    \n",
    "    # with params_out:\n",
    "        #    params_out.clear_output()\n",
    "        #   display(tr.show_curr_record_params())\n",
    "        \n",
    "        with stats_out:\n",
    "            stats_out.clear_output(wait=True)\n",
    "            display(dfx.show_train_metrics())\n",
    "\n",
    "        with cm_out:\n",
    "            cm_out.clear_output(wait=True)\n",
    "            display(dfx.show_confusion_matrix_train())\n",
    "\n",
    "        with roc_out:\n",
    "            roc_out.clear_output(wait=True)\n",
    "            display(dfx.show_ROC())\n",
    "\n",
    "        with det_out:\n",
    "            det_out.clear_output(wait=True)\n",
    "            display(dfx.show_DET())\n",
    "\n",
    "        with prec_recall_out:\n",
    "            prec_recall_out.clear_output(wait=True)\n",
    "            display(dfx.show_precision_recall())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    def test_model_on_oos(dfx,val):\n",
    "        \n",
    "        dfx.set_testing_model()\n",
    "    # with params_out:\n",
    "        #    params_out.clear_output()\n",
    "        #   display(tr.show_curr_record_params())\n",
    "\n",
    "        with stats_out:\n",
    "            stats_out.clear_output(wait=True)\n",
    "            display(dfx.show_test_metrics())\n",
    "\n",
    "        with cm_out:\n",
    "            cm_out.clear_output(wait=True)\n",
    "            display(dfx.show_confusion_matrix_train())\n",
    "\n",
    "        with roc_out:\n",
    "            roc_out.clear_output(wait=True)\n",
    "            display(dfx.show_ROC())\n",
    "\n",
    "        with det_out:\n",
    "            det_out.clear_output(wait=True)\n",
    "            display(dfx.show_DET())\n",
    "        \n",
    "        with prec_recall_out:\n",
    "            prec_recall_out.clear_output(wait=True)\n",
    "            display(dfx.show_precision_recall())\n",
    "        \n",
    "        with cm2_out:\n",
    "            cm2_out.clear_output(wait=True)\n",
    "            display(dfx.show_confusion_matrix_test())\n",
    "\n",
    "            \n",
    "\n",
    "        with test_metrics_out:\n",
    "            test_metrics_out.clear_output(wait=True)\n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    initialize()\n",
    "\n",
    "\n",
    "\n",
    "    rec_sel_dropdown.observe(partial(select_record_to_view,tr),names='value')\n",
    "    run_oos_button.on_click(partial(test_model_on_oos, tr))\n",
    "\n",
    "    return widgets.HBox([left_box, stat_box,chart_box])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 10.88 seconds for 28 candidate parameter settings.\n"
     ]
    }
   ],
   "source": [
    "#import src.ModelEvaluator.GridSearch as gs\n",
    "#import src.ModelEvaluator.ViewResults as vr\n",
    "#import src.ModelEvaluator.EvalViewController as evc\n",
    "\n",
    "#gridsearch = gs.GridCV(df)\n",
    "gridsearch = GridCV(df)\n",
    "results = gridsearch.perform_gridsearch()\n",
    "# there should be a funciton in dataframe that spits these out\n",
    "#tr = vr.ResultsViewer(results,vc.df.features_train,vc.df.labels_train,vc.df.features_test,vc.df.labels_test)\n",
    "#evc.eval_controller(tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc3a1c6899246d8a93a8785826e273a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Label(value='Select Record to View'), Dropdown(options=('1', '2', '3', '4', '5',â€¦"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr = ResultsViewer(results,df.features_train,df.labels_train,df.features_test,df.labels_test)\n",
    "eval_controller(tr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
