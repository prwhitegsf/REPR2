{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0b61c556e44e5e84756d17a7a8e46a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(VBox(children=(Label(value='Emotions'),)), SelectMultiple(index=(0,), layout=Lay…"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout\n",
    "from IPython.display import display\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import src.FeatureExplorer.DataController as datacontrol\n",
    "import src.FeatureExplorer.ViewController as vc\n",
    "\n",
    "df = datacontrol.dataframe('datasets/RAVDESS/metadata/RAVDESS.csv')\n",
    "vc.view_feature_controls(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import recall_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class GridCV:\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.features_train = df.features_train\n",
    "        self.label_train = df.labels_train\n",
    "\n",
    "\n",
    "    def perform_gridsearch(self):\n",
    "        param_grid={\n",
    "            \"C\" : [0.1,0.5,0.8,1.0,1.2,1.5,2],\n",
    "            \"gamma\" : [\"auto\",\"scale\"],\n",
    "            \"class_weight\" : [\"balanced\",None]\n",
    "        }\n",
    "\n",
    "\n",
    "        from time import time\n",
    "        cv = GroupKFold(5)\n",
    "        rng = np.random.RandomState(7)\n",
    "        groups = rng.randint(0, 10, size=len(self.label_train))\n",
    "        grid_search = GridSearchCV(SVC(kernel='rbf'), param_grid=param_grid,scoring='recall',cv=cv,return_train_score=True)\n",
    "        start = time()\n",
    "        grid_search.fit(self.features_train, self.label_train, groups=groups)\n",
    "\n",
    "        print(\n",
    "            \"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "            % (time() - start, len(grid_search.cv_results_[\"params\"]))\n",
    "        )\n",
    "        use_cols = ['param_C','param_class_weight',  'param_gamma', 'mean_test_score','mean_train_score','std_test_score', 'rank_test_score']\n",
    "        gr = pd.DataFrame(grid_search.cv_results_)[use_cols]\n",
    "        gr.sort_values(by='rank_test_score',inplace=True)\n",
    "        return gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results Viewer\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay,RocCurveDisplay,PrecisionRecallDisplay,DetCurveDisplay\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score,precision_score,accuracy_score,d2_absolute_error_score\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class ResultsViewer:\n",
    "\n",
    "    def __init__(self, df, features_train, labels_train,features_test, labels_test):\n",
    "        \n",
    "        self.df = self.arrange_columns(df)\n",
    "        \n",
    "        self.model = SVC()\n",
    "        self.current_record_idx = 0\n",
    "\n",
    "        self.features = features_train\n",
    "        self.labels = labels_train\n",
    "\n",
    "        self.features_train = features_train\n",
    "        self.labels_train = labels_train\n",
    "\n",
    "        # Testing only\n",
    "        self.features_test = features_test\n",
    "        self.labels_test = labels_test\n",
    "        self.test_model = None\n",
    "        self.test_mode = 0\n",
    "\n",
    "        self.predictions = []\n",
    "\n",
    "\n",
    "    def arrange_columns(self, in_df):\n",
    "        df = in_df.copy()\n",
    "        df['rank']=list(range(1,len(df)+1))\n",
    "        df.drop(columns=['rank_test_score'],inplace=True)\n",
    "        df.columns=['L2Mult','weight','gamma','test_recall','train_recall', 'test_stdev','rank']\n",
    "        df = df[['rank','L2Mult','weight','gamma','test_recall','train_recall', 'test_stdev']]\n",
    "        return df\n",
    "    \n",
    "\n",
    "    def get_top_records(self, num_records=10):\n",
    "        return self.df.iloc[0:num_records]\n",
    "\n",
    "    def format_top_records_table(self, recs,num_records=10):\n",
    "\n",
    "        cols = ['rank', 'weight','gamma','L2Mult','test recall', 'train recall']\n",
    "\n",
    "        cell_text = []\n",
    "        for i in range(num_records):\n",
    "            \n",
    "            weight = 'bal'\n",
    "            if recs['weight'].iloc[i] == None:\n",
    "                weight =\"unbal\"\n",
    "            \n",
    "            cell_text.append([recs['rank'].iloc[i], \n",
    "                              weight,\n",
    "                              recs['gamma'].iloc[i],\n",
    "                              round(recs['L2Mult'].iloc[i],7),\n",
    "                              round(recs['test_recall'].iloc[i],2),\n",
    "                              round(recs['train_recall'].iloc[i],2)])\n",
    "        return cols, cell_text\n",
    "\n",
    "    def print_records_to_table(self):\n",
    "       \n",
    "        cols, cell_text = self.format_top_records_table(self.get_top_records())\n",
    "\n",
    "        fig,ax = plt.subplots(figsize=(3,3),layout=\"constrained\")\n",
    "        fig.suptitle(\"Top Grid Search Results\")\n",
    "        \n",
    "        fig.patch.set_visible(False)\n",
    "        ax.axis('off')\n",
    "        ax.axis('tight')\n",
    "        fig.canvas.header_visible = False\n",
    "        \n",
    "        col_widths = [0.15,0.16,0.17,0.16,0.18,0.18]\n",
    "\n",
    "        table = ax.table(cellText=cell_text,colLabels=cols,loc='center',colWidths=col_widths)\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(8)\n",
    "        table.scale(1.5,1.5)\n",
    "        plt.close()\n",
    "        return fig\n",
    "    \n",
    "  \n",
    "  \n",
    "  ####################################################################################\n",
    "    \n",
    "    def select_record(self,idx):\n",
    "        plt.close()\n",
    "        self.current_record_idx = idx\n",
    "        self.fit_model_with_record(idx)\n",
    "\n",
    "    \n",
    "    def apply_record_to_model(self, rec_index=0):\n",
    "        \n",
    "        return SVC(C=self.df['L2Mult'].iloc[rec_index],\n",
    "                   kernel='rbf',\n",
    "                   gamma=self.df['gamma'].iloc[rec_index],\n",
    "                   class_weight=self.df['weight'].iloc[rec_index]\n",
    "                   )\n",
    "     \n",
    "           \n",
    "\n",
    "\n",
    "    def fit_model_with_record(self, rec_index=0):    \n",
    "        self.model = self.apply_record_to_model(rec_index=rec_index)\n",
    "        self.model = self.model.fit(self.features,self.labels)\n",
    "        return self.model\n",
    "       \n",
    "    def set_testing_model(self):\n",
    "        self.test_model = self.model\n",
    "        self.test_mode = 1\n",
    "        self.predictions = self.test_model.predict(self.features_test)\n",
    "\n",
    "\n",
    "\n",
    "    def show_confusion_matrix_train(self):\n",
    "        fig,axs = plt.subplots(figsize=(3,3), layout=\"constrained\")\n",
    "        axs.set_title(\"Confusion Matrix Train\")\n",
    "        ConfusionMatrixDisplay.from_estimator(self.model, self.features_train, self.labels_train,ax=axs,colorbar=False)\n",
    "        plt.close()\n",
    "        return fig\n",
    "\n",
    "    def show_confusion_matrix_test(self):\n",
    "        fig,axs = plt.subplots(figsize=(3,3), layout=\"constrained\")\n",
    "        axs.set_title(\"Confusion Matrix Test\")\n",
    "        if self.test_mode == 1:\n",
    "            ConfusionMatrixDisplay.from_predictions(self.labels_test,self.predictions,ax=axs,colorbar=False,cmap=\"magma\")\n",
    "        plt.close()\n",
    "        return fig\n",
    "\n",
    "    def show_ROC(self):\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(4,4),layout=\"constrained\")\n",
    "        fig.canvas.header_visible = False\n",
    "        ax.set_title(\"ROC Curve\")\n",
    "        RocCurveDisplay.from_estimator(self.model, self.features_train, self.labels_train,ax=ax,name=\"ROC Training\") \n",
    "        \n",
    "        if self.test_mode == 1:\n",
    "            pred = self.test_model.decision_function(self.features_test)\n",
    "            RocCurveDisplay.from_predictions(self.labels_test,pred,ax=ax,name=\"ROC Test\")\n",
    "        \n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.close()\n",
    "        return fig\n",
    "\n",
    "\n",
    "    def show_DET(self):\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(4,3),layout=\"constrained\")\n",
    "        ax.set_title(\"DET Curve\")\n",
    "        fig.canvas.header_visible = False\n",
    "        DetCurveDisplay.from_estimator(self.model, self.features_train, self.labels_train,ax=ax)\n",
    "        if self.test_mode == 1:\n",
    "            pred = self.test_model.decision_function(self.features_test)\n",
    "            DetCurveDisplay.from_predictions(self.labels_test,pred,ax=ax)\n",
    "        plt.ylabel('False Negative Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.close()\n",
    "        return fig\n",
    "\n",
    "    def show_precision_recall(self):\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(4,3),layout=\"constrained\")\n",
    "        fig.canvas.header_visible = False\n",
    "        ax.set_title(\"Precision Recall Curve (PRC)\")\n",
    "        PrecisionRecallDisplay.from_estimator(self.model, self.features_train, self.labels_train,ax=ax,name=\"PRC Train\",plot_chance_level=True) \n",
    "        \n",
    "        if self.test_mode == 1:\n",
    "            pred = self.test_model.decision_function(self.features_test)\n",
    "            PrecisionRecallDisplay.from_predictions(self.labels_test,pred,ax=ax,name=\"PRC Test\",plot_chance_level=True)\n",
    "        \n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.close()\n",
    "        return fig\n",
    "\n",
    "    def get_train_metrics(self):\n",
    "        # obtain scores\n",
    "        \n",
    "        scoring = ['recall','precision','accuracy','d2_absolute_error_score']\n",
    "        scores = cross_validate(self.model, self.features, self.labels,scoring=scoring)\n",
    "        \n",
    "        cols = ['recall','precision','accuracy','d2_error']\n",
    "        cells = []\n",
    "        cells.append(round(scores['test_recall'].mean(),2))\n",
    "        cells.append(round(scores['test_precision'].mean(),2))\n",
    "        \n",
    "        cells.append(round(scores['test_accuracy'].mean(),2))\n",
    "        #cells.append(round(scores['test_f1_micro'].mean(),2))\n",
    "        cells.append(round(scores['test_d2_absolute_error_score'].mean(),2))\n",
    "\n",
    "        return cols, cells\n",
    "\n",
    "\n",
    "    def get_test_metrics(self):\n",
    "        pred = self.test_model.decision_function(self.features_test)\n",
    "        cols = ['recall','recall_micro','precision','d2_error']\n",
    "        cells = []\n",
    "        cells.append(round(recall_score(self.labels_test, self.predictions),3))\n",
    "        cells.append(round(precision_score(self.labels_test, self.predictions),3))\n",
    "        cells.append(round(accuracy_score(self.labels_test, self.predictions),3))\n",
    "        cells.append(round(d2_absolute_error_score(self.labels_test,self.predictions),3))\n",
    "        \n",
    "        return cols, cells\n",
    "    \n",
    "    def show_train_metrics(self):\n",
    "        \n",
    "        cols, cell_text = self.get_train_metrics()\n",
    "        rows = [\"Train Results\"]\n",
    "        fig,axs = plt.subplots(figsize=(2,2))\n",
    "        fig.suptitle(\"Model Performance\")\n",
    "        fig.canvas.header_visible = False\n",
    "        fig.patch.set_visible(False)\n",
    "        axs.axis('off')\n",
    "        axs.axis('tight')\n",
    "        \n",
    "        table = axs.table( colLabels=cols,rowLabels=rows,cellText=[cell_text],loc='center')\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(8)\n",
    "        table.scale(1.5,1.5)\n",
    "        plt.close()\n",
    "        return fig\n",
    "\n",
    "    def show_test_metrics(self):\n",
    "        cols , train_row = self.get_train_metrics()\n",
    "        _, test_row = self.get_test_metrics()\n",
    "        \n",
    "        \n",
    "        rows = [\"Training\",\"Testing\"]\n",
    "        fig,axs = plt.subplots(figsize=(3,2))\n",
    "        fig.suptitle(\"Model Performance\")\n",
    "        fig.canvas.header_visible = False\n",
    "        fig.patch.set_visible(False)\n",
    "        axs.axis('off')\n",
    "        axs.axis('tight')\n",
    "        \n",
    "        table = axs.table( colLabels=cols,rowLabels=rows,cellText=[train_row, test_row],loc='center')\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(8)\n",
    "        table.scale(1.5,1.5)\n",
    "        plt.close()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval view controller\n",
    "def eval_controller(tr):\n",
    "\n",
    "    tr.fit_model_with_record(0)\n",
    "\n",
    "    rec_sel_label = widgets.Label(value=\"Select Record to View\")\n",
    "\n",
    "    rec_sel_dropdown = widgets.Dropdown(\n",
    "        options=['1','2','3','4','5','6','7','8','9','10'],\n",
    "        value='1',\n",
    "        description='',\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "\n",
    "    # Handlers\n",
    "    params_out = widgets.Output()\n",
    "    record_out = widgets.Output()\n",
    "    roc_out = widgets.Output()\n",
    "    det_out = widgets.Output()\n",
    "    stats_out =  widgets.Output()\n",
    "    cm_out = widgets.Output()\n",
    "    cm2_out = widgets.Output()\n",
    "    prec_recall_out = widgets.Output()\n",
    "    test_metrics_out = widgets.Output()\n",
    "\n",
    "    run_oos_button  = widgets.Button(description='Test model on out of sample data')\n",
    "\n",
    "    record_box = widgets.VBox([rec_sel_label,rec_sel_dropdown,record_out,prec_recall_out,run_oos_button])\n",
    "\n",
    "    model_box = widgets.VBox([test_metrics_out,prec_recall_out])\n",
    "    stat_box = widgets.VBox([stats_out,cm_out,cm2_out])\n",
    "    chart_box = widgets.VBox([roc_out, det_out])\n",
    "    left_box = record_box\n",
    "\n",
    "\n",
    "    def initialize():\n",
    "        \n",
    "        #with params_out:\n",
    "        #   params_out.clear_output()\n",
    "        #  display(tr.show_curr_record_params())\n",
    "\n",
    "        with record_out:\n",
    "\n",
    "            record_out.clear_output(wait=True)\n",
    "            display(tr.print_records_to_table())\n",
    "\n",
    "        with stats_out:\n",
    "            stats_out.clear_output(wait=True)\n",
    "            display(tr.show_train_metrics())\n",
    "\n",
    "        with cm2_out:\n",
    "            cm2_out.clear_output(wait=True)\n",
    "\n",
    "        with cm_out:\n",
    "            cm_out.clear_output(wait=True)\n",
    "            display(tr.show_confusion_matrix_train())\n",
    "\n",
    "        with roc_out:\n",
    "            roc_out.clear_output(wait=True)\n",
    "            display(tr.show_ROC())\n",
    "\n",
    "        with det_out:\n",
    "            det_out.clear_output(wait=True)\n",
    "            display(tr.show_DET())\n",
    "        \n",
    "        \n",
    "\n",
    "        with prec_recall_out:\n",
    "            prec_recall_out.clear_output(wait=True)\n",
    "            display(tr.show_precision_recall())\n",
    "\n",
    "    def select_record_to_view(dfx,names):\n",
    "        left_box = record_box\n",
    "        val = int(names.new) - 1\n",
    "        dfx.select_record(val)\n",
    "    \n",
    "    # with params_out:\n",
    "        #    params_out.clear_output()\n",
    "        #   display(tr.show_curr_record_params())\n",
    "        \n",
    "        with stats_out:\n",
    "            stats_out.clear_output(wait=True)\n",
    "            display(dfx.show_train_metrics())\n",
    "\n",
    "        with cm_out:\n",
    "            cm_out.clear_output(wait=True)\n",
    "            display(dfx.show_confusion_matrix_train())\n",
    "\n",
    "        with roc_out:\n",
    "            roc_out.clear_output(wait=True)\n",
    "            display(dfx.show_ROC())\n",
    "\n",
    "        with det_out:\n",
    "            det_out.clear_output(wait=True)\n",
    "            display(dfx.show_DET())\n",
    "\n",
    "        with prec_recall_out:\n",
    "            prec_recall_out.clear_output(wait=True)\n",
    "            display(dfx.show_precision_recall())\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    def test_model_on_oos(dfx,val):\n",
    "        \n",
    "        dfx.set_testing_model()\n",
    "    # with params_out:\n",
    "        #    params_out.clear_output()\n",
    "        #   display(tr.show_curr_record_params())\n",
    "\n",
    "        with stats_out:\n",
    "            stats_out.clear_output(wait=True)\n",
    "            display(dfx.show_test_metrics())\n",
    "\n",
    "        with cm_out:\n",
    "            cm_out.clear_output(wait=True)\n",
    "            display(dfx.show_confusion_matrix_train())\n",
    "\n",
    "        with roc_out:\n",
    "            roc_out.clear_output(wait=True)\n",
    "            display(dfx.show_ROC())\n",
    "\n",
    "        with det_out:\n",
    "            det_out.clear_output(wait=True)\n",
    "            display(dfx.show_DET())\n",
    "        \n",
    "        with prec_recall_out:\n",
    "            prec_recall_out.clear_output(wait=True)\n",
    "            display(dfx.show_precision_recall())\n",
    "        \n",
    "        with cm2_out:\n",
    "            cm2_out.clear_output(wait=True)\n",
    "            display(dfx.show_confusion_matrix_test())\n",
    "\n",
    "            \n",
    "\n",
    "        with test_metrics_out:\n",
    "            test_metrics_out.clear_output(wait=True)\n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    initialize()\n",
    "\n",
    "\n",
    "\n",
    "    rec_sel_dropdown.observe(partial(select_record_to_view,tr),names='value')\n",
    "    run_oos_button.on_click(partial(test_model_on_oos, tr))\n",
    "\n",
    "    return widgets.HBox([left_box, stat_box,chart_box])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 9.99 seconds for 28 candidate parameter settings.\n"
     ]
    }
   ],
   "source": [
    "#import src.ModelEvaluator.GridSearch as gs\n",
    "#import src.ModelEvaluator.ViewResults as vr\n",
    "#import src.ModelEvaluator.EvalViewController as evc\n",
    "\n",
    "#gridsearch = gs.GridCV(df)\n",
    "gridsearch = GridCV(df)\n",
    "results = gridsearch.perform_gridsearch()\n",
    "# there should be a funciton in dataframe that spits these out\n",
    "#tr = vr.ResultsViewer(results,vc.df.features_train,vc.df.labels_train,vc.df.features_test,vc.df.labels_test)\n",
    "#evc.eval_controller(tr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c6bdd62d2f48f68af2251045de93fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Label(value='Select Record to View'), Dropdown(options=('1', '2', '3', '4', '5',…"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No such comm: 291ee03d0d1249718ba20b000ccc9c2b\n",
      "No such comm: 291ee03d0d1249718ba20b000ccc9c2b\n",
      "No such comm: 291ee03d0d1249718ba20b000ccc9c2b\n",
      "No such comm: 47fad5f70df3433babfe5c864459a376\n",
      "No such comm: 47fad5f70df3433babfe5c864459a376\n",
      "No such comm: 47fad5f70df3433babfe5c864459a376\n",
      "No such comm: 390df7f19b4e4a75a7e976803bb3824e\n",
      "No such comm: 390df7f19b4e4a75a7e976803bb3824e\n",
      "No such comm: 390df7f19b4e4a75a7e976803bb3824e\n",
      "No such comm: 3ef6b5982e894cbeb652159e823f652f\n",
      "No such comm: 3ef6b5982e894cbeb652159e823f652f\n",
      "No such comm: 3ef6b5982e894cbeb652159e823f652f\n",
      "No such comm: 6a7b81c3147649338bf149b08077f6a1\n",
      "No such comm: 6a7b81c3147649338bf149b08077f6a1\n",
      "No such comm: 6a7b81c3147649338bf149b08077f6a1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No such comm: ca92a0865a1149768389cb79c904de30\n",
      "No such comm: ca92a0865a1149768389cb79c904de30\n",
      "No such comm: ca92a0865a1149768389cb79c904de30\n",
      "No such comm: f7119b9ec7fc4d308c4fe607a9c27e50\n",
      "No such comm: f7119b9ec7fc4d308c4fe607a9c27e50\n",
      "No such comm: f7119b9ec7fc4d308c4fe607a9c27e50\n",
      "No such comm: 0df11b4a66d94e3aad51ba0afe5c0cea\n",
      "No such comm: 0df11b4a66d94e3aad51ba0afe5c0cea\n",
      "No such comm: 0df11b4a66d94e3aad51ba0afe5c0cea\n",
      "No such comm: 458a0bc231f844ca821450824b02f9c3\n",
      "No such comm: 458a0bc231f844ca821450824b02f9c3\n",
      "No such comm: 458a0bc231f844ca821450824b02f9c3\n",
      "No such comm: b5bac4c32e77499ca93e8237f351e4e1\n",
      "No such comm: b5bac4c32e77499ca93e8237f351e4e1\n",
      "No such comm: b5bac4c32e77499ca93e8237f351e4e1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No such comm: cac761e730d34bcd91eff136e6aaed9e\n",
      "No such comm: cac761e730d34bcd91eff136e6aaed9e\n",
      "No such comm: cac761e730d34bcd91eff136e6aaed9e\n",
      "No such comm: 1810a662e3a144cfb5e4efc1b9ccea41\n",
      "No such comm: 1810a662e3a144cfb5e4efc1b9ccea41\n",
      "No such comm: 1810a662e3a144cfb5e4efc1b9ccea41\n",
      "No such comm: 4aa5c92742424a7babd7bf5bb4c3008a\n",
      "No such comm: 4aa5c92742424a7babd7bf5bb4c3008a\n",
      "No such comm: 4aa5c92742424a7babd7bf5bb4c3008a\n",
      "No such comm: 686e348366274a9483191fa93c2e7413\n",
      "No such comm: 686e348366274a9483191fa93c2e7413\n",
      "No such comm: 686e348366274a9483191fa93c2e7413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No such comm: 244e5a05d1cd44f9878c96ddecc08162\n",
      "No such comm: 244e5a05d1cd44f9878c96ddecc08162\n",
      "No such comm: 244e5a05d1cd44f9878c96ddecc08162\n",
      "No such comm: 331812321bbb41fdb98f524574ef4902\n",
      "No such comm: 331812321bbb41fdb98f524574ef4902\n",
      "No such comm: 331812321bbb41fdb98f524574ef4902\n",
      "No such comm: 10693dd667c54e20b138b74aa4cfa830\n",
      "No such comm: 10693dd667c54e20b138b74aa4cfa830\n",
      "No such comm: 10693dd667c54e20b138b74aa4cfa830\n",
      "No such comm: 0061a778ea41404d95613d8acaa7b539\n",
      "No such comm: 0061a778ea41404d95613d8acaa7b539\n",
      "No such comm: 0061a778ea41404d95613d8acaa7b539\n",
      "No such comm: f75afe3cb3a84827943ef7df0bc7c08f\n",
      "No such comm: f75afe3cb3a84827943ef7df0bc7c08f\n",
      "No such comm: f75afe3cb3a84827943ef7df0bc7c08f\n"
     ]
    }
   ],
   "source": [
    "tr = ResultsViewer(results,df.features_train,df.labels_train,df.features_test,df.labels_test)\n",
    "eval_controller(tr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
