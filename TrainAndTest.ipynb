{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout, AppLayout\n",
    "from IPython.display import display\n",
    "from IPython.display import Audio\n",
    "from functools import partial\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import src.FeatureExtractors as fe\n",
    "from matplotlib.colors import Normalize\n",
    "import sklearn\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# get our meta data\n",
    "df = pd.read_csv('datasets/RAVDESS/metadata/RAVDESS.csv',usecols=['actor','actor_sex','emotion','label','filepath'])\n",
    "\n",
    "# Choose the feature set(s) and add to dataframe\n",
    "\n",
    "def choose_features(mfcc=40, mel=128):\n",
    "    scaler = StandardScaler()\n",
    "    #features = scaler.fit_transform(features)\n",
    "    # mfcc only\n",
    "    if mfcc != 'None' and mel == 'None':\n",
    "        return scaler.fit_transform(np.load(f'datasets/RAVDESS/features/mfcc/mfcc{mfcc}.npy'))\n",
    "    # mels only\n",
    "    elif mfcc == 'None' and mel != 'None':\n",
    "        return scaler.fit_transform(np.load(f'datasets/RAVDESS/features/mel/mel{mel}.npy'))\n",
    "    # both\n",
    "    elif mfcc != 'None' and mel != 'None':\n",
    "        mfcc_frame = np.load(f'datasets/RAVDESS/features/mfcc/mfcc{mfcc}.npy')\n",
    "        mel_frame = np.load(f'datasets/RAVDESS/features/mel/mel{mel}.npy')\n",
    "        feature_matrix=np.array([])\n",
    "        feature_matrix = np.hstack((mfcc_frame, mel_frame))\n",
    "        return scaler.fit_transform(feature_matrix)\n",
    "\n",
    "\n",
    "\n",
    "df['features'] = list(choose_features(40,128))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# split data set functions\n",
    "def random_split(df,test_size=0.2):\n",
    "    labels = np.array(df['label'])\n",
    "    features = np.vstack(df['features'])\n",
    "    \n",
    "    return train_test_split(features, labels,test_size=test_size,random_state=69)\n",
    "\n",
    "\n",
    "def split_by_actor_sex(df,train_set='male'):\n",
    "    train = df\n",
    "    test = df\n",
    "    if train_set == 'male':\n",
    "        train = df[df['actor_sex'] == 'male']\n",
    "        test = df[df['actor_sex'] == 'female']\n",
    "    elif train_set == 'female':\n",
    "        train = df[df['actor_sex'] == 'female']\n",
    "        test = df[df['actor_sex'] == 'male']\n",
    "\n",
    "    # , np.vstack(test['features']),np.array(train['label'],np.array(test['label']))\n",
    "    return np.vstack(train['features']), np.vstack(test['features']), np.array(train['label']),np.array(test['label'])\n",
    "\n",
    "\n",
    "# CV scoring function -- if I end up wanting it, which maybe I don't?\n",
    "sklearn.set_config(enable_metadata_routing=True)\n",
    "def get_model_cv_scores(model, features, labels):\n",
    "    cv = GroupKFold(5)\n",
    "    rng = np.random.RandomState(7)\n",
    "    groups = rng.randint(0, 10, size=len(labels))\n",
    "    scoring = ['recall_micro', 'precision_micro','f1_micro','balanced_accuracy','roc_auc']\n",
    "    scores = cross_validate(model, features, labels,scoring=scoring,cv=cv, params={\"groups\":groups})\n",
    "    return pd.DataFrame(scores)\n",
    "\n",
    "# Split the dataset into training and tests -- \n",
    "feature_train,feature_test,label_train,label_test = random_split(df, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV took 23.14 seconds for 28 candidate parameter settings.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import recall_score, balanced_accuracy_score\n",
    "param_grid={\n",
    "    \"C\" : [0.1,0.5,0.8,1.0,1.2,1.3],\n",
    "    \"kernel\" : ['rbf','poly'],\n",
    "    \"degree\" : [2,3,4],\n",
    "    \"gamma\" : [\"auto\",\"scale\"],\n",
    "    \"class_weight\" : [\"balanced\",None]\n",
    "}\n",
    "\n",
    "\n",
    "from time import time\n",
    "cv = GroupKFold(5)\n",
    "rng = np.random.RandomState(7)\n",
    "groups = rng.randint(0, 10, size=len(label_train))\n",
    "grid_search = GridSearchCV(SVC(), param_grid=param_grid,scoring='recall',cv=cv,return_train_score=True)\n",
    "start = time()\n",
    "grid_search.fit(feature_train, label_train, groups=groups)\n",
    "\n",
    "print(\n",
    "    \"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "    % (time() - start, len(grid_search.cv_results_[\"params\"]))\n",
    ")\n",
    "use_cols = ['param_C','param_class_weight', 'param_degree', 'param_gamma', 'param_kernel',\n",
    "        'mean_test_score','mean_train_score','std_test_score', 'rank_test_score']\n",
    "gr = pd.DataFrame(grid_search.cv_results_)[use_cols]\n",
    "gr.sort_values(by='rank_test_score',inplace=True)\n",
    "gr.drop_duplicates(subset=['param_kernel','rank_test_score'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.707572</td>\n",
       "      <td>0.873410</td>\n",
       "      <td>0.058602</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.2</td>\n",
       "      <td>balanced</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.700429</td>\n",
       "      <td>0.880893</td>\n",
       "      <td>0.071225</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>balanced</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.687095</td>\n",
       "      <td>0.827345</td>\n",
       "      <td>0.070048</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>balanced</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.687095</td>\n",
       "      <td>0.841677</td>\n",
       "      <td>0.070048</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.2</td>\n",
       "      <td>balanced</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.674595</td>\n",
       "      <td>0.844142</td>\n",
       "      <td>0.074307</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8</td>\n",
       "      <td>balanced</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.671257</td>\n",
       "      <td>0.813426</td>\n",
       "      <td>0.072665</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>balanced</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.669704</td>\n",
       "      <td>0.798868</td>\n",
       "      <td>0.052861</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.651614</td>\n",
       "      <td>0.772117</td>\n",
       "      <td>0.086377</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.0</td>\n",
       "      <td>balanced</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.642496</td>\n",
       "      <td>0.923925</td>\n",
       "      <td>0.196964</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.639114</td>\n",
       "      <td>0.745747</td>\n",
       "      <td>0.093549</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.0</td>\n",
       "      <td>balanced</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.635353</td>\n",
       "      <td>0.943550</td>\n",
       "      <td>0.198756</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.616662</td>\n",
       "      <td>0.897558</td>\n",
       "      <td>0.181411</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.552870</td>\n",
       "      <td>0.597468</td>\n",
       "      <td>0.116297</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.544174</td>\n",
       "      <td>0.575455</td>\n",
       "      <td>0.110001</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.429315</td>\n",
       "      <td>0.539076</td>\n",
       "      <td>0.110272</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.422173</td>\n",
       "      <td>0.458991</td>\n",
       "      <td>0.117920</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.5</td>\n",
       "      <td>None</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.422173</td>\n",
       "      <td>0.524355</td>\n",
       "      <td>0.117920</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.5</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.422173</td>\n",
       "      <td>0.512300</td>\n",
       "      <td>0.117920</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.2</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.422173</td>\n",
       "      <td>0.490069</td>\n",
       "      <td>0.117920</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.422173</td>\n",
       "      <td>0.533976</td>\n",
       "      <td>0.117920</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.422173</td>\n",
       "      <td>0.483468</td>\n",
       "      <td>0.117920</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.2</td>\n",
       "      <td>None</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.422173</td>\n",
       "      <td>0.504952</td>\n",
       "      <td>0.117920</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.8</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.413477</td>\n",
       "      <td>0.442604</td>\n",
       "      <td>0.111696</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.8</td>\n",
       "      <td>None</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.322568</td>\n",
       "      <td>0.447482</td>\n",
       "      <td>0.115211</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.213851</td>\n",
       "      <td>0.423226</td>\n",
       "      <td>0.154870</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.423034</td>\n",
       "      <td>0.166132</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>scale</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_C param_class_weight param_gamma  mean_test_score  mean_train_score  \\\n",
       "20      1.5           balanced        auto         0.707572          0.873410   \n",
       "17      1.2           balanced       scale         0.700429          0.880893   \n",
       "12      1.0           balanced        auto         0.687095          0.827345   \n",
       "13      1.0           balanced       scale         0.687095          0.841677   \n",
       "16      1.2           balanced        auto         0.674595          0.844142   \n",
       "9       0.8           balanced       scale         0.671257          0.813426   \n",
       "8       0.8           balanced        auto         0.669704          0.798868   \n",
       "5       0.5           balanced       scale         0.651614          0.772117   \n",
       "24      2.0           balanced        auto         0.642496          0.923925   \n",
       "4       0.5           balanced        auto         0.639114          0.745747   \n",
       "25      2.0           balanced       scale         0.635353          0.943550   \n",
       "21      1.5           balanced       scale         0.616662          0.897558   \n",
       "1       0.1           balanced       scale         0.552870          0.597468   \n",
       "0       0.1           balanced        auto         0.544174          0.575455   \n",
       "27      2.0               None       scale         0.429315          0.539076   \n",
       "14      1.0               None        auto         0.422173          0.458991   \n",
       "23      1.5               None       scale         0.422173          0.524355   \n",
       "22      1.5               None        auto         0.422173          0.512300   \n",
       "18      1.2               None        auto         0.422173          0.490069   \n",
       "26      2.0               None        auto         0.422173          0.533976   \n",
       "15      1.0               None       scale         0.422173          0.483468   \n",
       "19      1.2               None       scale         0.422173          0.504952   \n",
       "10      0.8               None        auto         0.413477          0.442604   \n",
       "11      0.8               None       scale         0.322568          0.447482   \n",
       "6       0.5               None        auto         0.213851          0.423226   \n",
       "7       0.5               None       scale         0.130000          0.423034   \n",
       "3       0.1               None       scale         0.000000          0.000000   \n",
       "2       0.1               None        auto         0.000000          0.000000   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "20        0.058602                1  \n",
       "17        0.071225                2  \n",
       "12        0.070048                3  \n",
       "13        0.070048                3  \n",
       "16        0.074307                5  \n",
       "9         0.072665                6  \n",
       "8         0.052861                7  \n",
       "5         0.086377                8  \n",
       "24        0.196964                9  \n",
       "4         0.093549               10  \n",
       "25        0.198756               11  \n",
       "21        0.181411               12  \n",
       "1         0.116297               13  \n",
       "0         0.110001               14  \n",
       "27        0.110272               15  \n",
       "14        0.117920               16  \n",
       "23        0.117920               16  \n",
       "22        0.117920               16  \n",
       "18        0.117920               16  \n",
       "26        0.117920               16  \n",
       "15        0.117920               16  \n",
       "19        0.117920               16  \n",
       "10        0.111696               23  \n",
       "11        0.115211               24  \n",
       "6         0.154870               25  \n",
       "7         0.166132               26  \n",
       "3         0.000000               27  \n",
       "2         0.000000               27  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableBuilder:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        pass\n",
    "\n",
    "    def top_five_table(self, recs):\n",
    "\n",
    "        cols = ['rank', 'kernel', 'L2Mult','test recall', 'train recall']\n",
    "        cell_text = []\n",
    "        for i in range(5):\n",
    "            cell_text.append([recs['rank'].iloc[i], \n",
    "                              recs['kernel'].iloc[i],\n",
    "                              round(recs['L2Mult'].iloc[i],7),\n",
    "                              round(recs['test_recall'].iloc[i],2),\n",
    "                              round(recs['train_recall'].iloc[i],2)])\n",
    "        return cols, cell_text\n",
    "    \n",
    "    def extend_cols(self,rec):\n",
    "        if rec['kernel']    == 'rbf': return ['gamma','weight']\n",
    "        elif rec['kernel']  == 'poly':return ['degree','weight']\n",
    "        elif rec['kernel']  == 'linear':return ['weight']\n",
    "       \n",
    "    def extend_cells(self, rec):\n",
    "        if rec['kernel']   == 'rbf':return [str(rec['gamma']), rec['weight']]\n",
    "        elif rec['kernel'] == 'poly': return [str(rec['poly_deg']), rec['weight']]\n",
    "        elif rec['kernel'] == 'linear': return rec['weight']\n",
    "\n",
    "    \n",
    "    def format_record_params(self, record):\n",
    "        cols = ['rank', 'kernel','L2Mult']\n",
    "        cols.extend(self.extend_cols(record))\n",
    "        cell_text = [str(record['rank']), record['kernel'],str(round(record['L2Mult'],7))]\n",
    "        cell_text.extend(self.extend_cells(record))\n",
    "        return cols, cell_text\n",
    "\n",
    "    # receive cv inputs as dataframerecord\n",
    "    def format_current_training_record(self, record, cv_results):\n",
    "        \n",
    "        precision = round(cv_results['test_precision_micro'].mean(),2)\n",
    "        accuracy  = round(cv_results['test_accuracy'].mean(),3)\n",
    "\n",
    "      \n",
    "        cell_text=[str(record['rank']), record['kernel'],str(precision),str(accuracy)]\n",
    "        cols = ['rank', 'kernel', 'precision', 'accuracy']\n",
    "        # add additional colls/values based on kernel type\n",
    "        cols.extend(self.extend_cols(record))\n",
    "        cell_text.extend(self.extend_cells(record))\n",
    "        return cols, cell_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x27f47ac9fd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay,RocCurveDisplay,PrecisionRecallDisplay,DetCurveDisplay\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score,precision_score,f1_score,hinge_loss,accuracy_score,d2_absolute_error_score\n",
    "\n",
    "class TrainingViewer:\n",
    "\n",
    "    def __init__(self, df, features_train, labels_train,features_test, labels_test):\n",
    "        \n",
    "        self.df = self.arrange_columns(df)\n",
    "        \n",
    "        self.model = SVC()\n",
    "        self.current_record_idx = 0\n",
    "\n",
    "        self.features = features_train\n",
    "        self.labels = labels_train\n",
    "\n",
    "        self.features_train = features_train\n",
    "        self.labels_train = labels_train\n",
    "\n",
    "        # Testing only\n",
    "        self.features_test = features_test\n",
    "        self.labels_test = labels_test\n",
    "        self.test_model = None\n",
    "        self.test_mode = 0\n",
    "\n",
    "        self.predictions = []\n",
    "\n",
    "\n",
    "    def arrange_columns(self, in_df):\n",
    "        df = in_df.copy()\n",
    "        df['rank']=list(range(1,len(df)+1))\n",
    "        df.drop(columns=['rank_test_score'],inplace=True)\n",
    "        df.columns=['L2Mult','weight','poly_deg','gamma','kernel','test_recall','train_recall', 'test_stdev','rank']\n",
    "        df = df[['rank','kernel','L2Mult','weight','poly_deg','gamma','test_recall','train_recall', 'test_stdev']]\n",
    "        return df\n",
    "    \n",
    "\n",
    "    def get_top_five_records(self):\n",
    "        return self.df.iloc[0:5]\n",
    "\n",
    "\n",
    "    def print_records_to_table(self):\n",
    "        tb = TableBuilder()\n",
    "        cols, cell_text = tb.top_five_table(self.get_top_five_records())\n",
    "\n",
    "        fig,ax = plt.subplots(figsize=(3,2.5))\n",
    "        fig.suptitle(\"Top Five Results\")\n",
    "        fig.patch.set_visible(False)\n",
    "        ax.axis('off')\n",
    "        ax.axis('tight')\n",
    "        fig.canvas.header_visible = False\n",
    "        \n",
    "        table = ax.table(cellText=cell_text,colLabels=cols,loc='center')\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(8)\n",
    "        table.scale(1.25,2)\n",
    "        plt.close()\n",
    "        return fig\n",
    "    \n",
    "\n",
    "    def show_box_plot(self):\n",
    "        by_kernel = {'rbf' : self.df['test_recall'][self.df['kernel'] == 'rbf'],\n",
    "             #'linear':  self.df['test_recall'][self.df['kernel'] == 'linear'],\n",
    "             'poly':  self.df['test_recall'][self.df['kernel'] == 'poly']}\n",
    "\n",
    "        bx=pd.DataFrame(by_kernel,index=None)\n",
    "        fig, ax = plt.subplots( figsize=(3,3),layout=\"tight\",num=None)\n",
    "    \n",
    "        ax.set_title(\"Kernel Boxplot\")\n",
    "        fig.canvas.header_visible = False\n",
    "\n",
    "        fig.canvas.toolbar_position = 'bottom'\n",
    "        ax.grid(True)    \n",
    "        line = ax.boxplot(bx.describe(),positions=[2,4], widths=1.5, patch_artist=True,\n",
    "                        showmeans=False, showfliers=False,tick_labels=['rbf','poly'],\n",
    "                        medianprops={\"color\": \"white\", \"linewidth\": 0.5},\n",
    "                        boxprops={\"facecolor\": \"C0\", \"edgecolor\": \"white\",\n",
    "                                \"linewidth\": 0.5},\n",
    "                        whiskerprops={\"color\": \"C0\", \"linewidth\": 1.5},\n",
    "                        capprops={\"color\": \"C0\", \"linewidth\": 1.5})\n",
    "        plt.close()\n",
    "        return fig\n",
    "  \n",
    "  \n",
    "  ####################################################################################\n",
    "    \n",
    "    def select_record(self,idx):\n",
    "        plt.close()\n",
    "        self.current_record_idx = idx\n",
    "        self.fit_model_with_record(idx)\n",
    "\n",
    "    \n",
    "    def apply_record_to_model(self, rec_index=0):\n",
    "        if self.df['kernel'].iloc[rec_index] == 'rbf':\n",
    "            return SVC(C=self.df['L2Mult'].iloc[rec_index],kernel='rbf',gamma=self.df['gamma'].iloc[rec_index],class_weight=self.df['weight'].iloc[rec_index])\n",
    "        elif self.df['kernel'].iloc[rec_index] == 'poly':\n",
    "            return SVC(C=self.df['L2Mult'].iloc[rec_index],kernel='poly',degree=self.df['poly_deg'].iloc[rec_index],class_weight=self.df['weight'].iloc[rec_index] )\n",
    "        elif self.df['kernel'].iloc[rec_index] == 'linear':\n",
    "            return SVC(C=self.df['L2Mult'].iloc[rec_index],kernel='linear',class_weight=self.df['weight'].iloc[rec_index] )\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "    def fit_model_with_record(self, rec_index=0):    \n",
    "        self.model = self.apply_record_to_model(rec_index=rec_index)\n",
    "        self.model = self.model.fit(self.features,self.labels)\n",
    "        return self.model\n",
    "       \n",
    "    def set_testing_model(self):\n",
    "        self.test_model = self.model\n",
    "        self.test_mode = 1\n",
    "        self.predictions = self.test_model.predict(self.features_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_model_cv_scores(self):\n",
    "        scoring = ['recall_micro', 'precision_micro','accuracy']\n",
    "        scores = cross_validate(self.model, self.features, self.labels,scoring=scoring)\n",
    "        res = pd.DataFrame(scores)\n",
    "        return res\n",
    "\n",
    "\n",
    "    def replace_class_weight(self):\n",
    "        rec = self.df.iloc[self.current_record_idx].copy()\n",
    "        if rec[\"weight\"] == None: rec[\"weight\"] = \"unbal\"\n",
    "        return rec\n",
    "    \n",
    "\n",
    "    def show_curr_record_params(self):\n",
    "        \n",
    "        tb = TableBuilder()\n",
    "        cols, cell_text = tb.format_record_params(self.replace_class_weight())\n",
    "        fig,axs = plt.subplots(figsize=(2,2))\n",
    "        fig.suptitle(\"Current Record Params\")\n",
    "        fig.canvas.header_visible = False\n",
    "        fig.patch.set_visible(False)\n",
    "        axs.axis('off')\n",
    "        axs.axis('tight')\n",
    "        \n",
    "        table = axs.table( colLabels=cols,cellText=[cell_text],loc='center')\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(8)\n",
    "        table.scale(2,2)\n",
    "        plt.close()\n",
    "        return fig\n",
    "\n",
    "\n",
    "    def show_record_stats_table(self):\n",
    "        tb = TableBuilder()\n",
    "        cols, cell_text = tb.format_current_training_record(self.replace_class_weight(),\n",
    "                                                            self.get_model_cv_scores())\n",
    "         \n",
    "        fig,axs = plt.subplots(figsize=(3,2))\n",
    "        fig.suptitle(\"Selected Record\")\n",
    "        fig.canvas.header_visible = False\n",
    "        fig.patch.set_visible(False)\n",
    "        axs.axis('off')\n",
    "        axs.axis('tight')\n",
    "        \n",
    "        table = axs.table( colLabels=cols,cellText=[cell_text],loc='center')\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(8)\n",
    "        table.scale(2,2)\n",
    "        plt.close()\n",
    "        return fig\n",
    "\n",
    "\n",
    "    def show_confusion_matrix_train(self):\n",
    "        fig,axs = plt.subplots(figsize=(3,3), layout=\"constrained\")\n",
    "        axs.set_title(\"Confusion Matrix Train\")\n",
    "        ConfusionMatrixDisplay.from_estimator(self.model, self.features_train, self.labels_train,ax=axs,colorbar=False)\n",
    "        plt.close()\n",
    "        return fig\n",
    "\n",
    "    def show_confusion_matrix_test(self):\n",
    "        fig,axs = plt.subplots(figsize=(3,3), layout=\"constrained\")\n",
    "        axs.set_title(\"Confusion Matrix Test\")\n",
    "        if self.test_mode == 1:\n",
    "            ConfusionMatrixDisplay.from_predictions(self.labels_test,self.predictions,ax=axs,colorbar=False,cmap=\"magma\")\n",
    "        plt.close()\n",
    "        return fig\n",
    "\n",
    "    def show_ROC(self):\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(4,4),layout=\"constrained\")\n",
    "        fig.canvas.header_visible = False\n",
    "        ax.set_title(\"ROC Curve\")\n",
    "        RocCurveDisplay.from_estimator(self.model, self.features_train, self.labels_train,ax=ax,name=\"ROC Training\") \n",
    "        \n",
    "        if self.test_mode == 1:\n",
    "            pred = self.test_model.decision_function(self.features_test)\n",
    "            RocCurveDisplay.from_predictions(self.labels_test,pred,ax=ax,name=\"ROC Test\")\n",
    "        \n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.close()\n",
    "        return fig\n",
    "\n",
    "\n",
    "    def show_DET(self):\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(4,3),layout=\"constrained\")\n",
    "        ax.set_title(\"DET Curve\")\n",
    "        fig.canvas.header_visible = False\n",
    "        DetCurveDisplay.from_estimator(self.model, self.features_train, self.labels_train,ax=ax)\n",
    "        if self.test_mode == 1:\n",
    "            pred = self.test_model.decision_function(self.features_test)\n",
    "            DetCurveDisplay.from_predictions(self.labels_test,pred,ax=ax)\n",
    "        plt.ylabel('False Negative Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.close()\n",
    "        return fig\n",
    "\n",
    "    def show_precision_recall(self):\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(4,3),layout=\"constrained\")\n",
    "        fig.canvas.header_visible = False\n",
    "        ax.set_title(\"Precision Recall Curve (PRC)\")\n",
    "        PrecisionRecallDisplay.from_estimator(self.model, self.features_train, self.labels_train,ax=ax,name=\"PRC Train\",plot_chance_level=True) \n",
    "        \n",
    "        if self.test_mode == 1:\n",
    "            pred = self.test_model.decision_function(self.features_test)\n",
    "            PrecisionRecallDisplay.from_predictions(self.labels_test,pred,ax=ax,name=\"PRC Test\",plot_chance_level=True)\n",
    "        \n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.close()\n",
    "        return fig\n",
    "\n",
    "    def get_train_metrics(self):\n",
    "        # obtain scores\n",
    "        \n",
    "        scoring = ['recall','recall_micro','precision_micro','d2_absolute_error_score']\n",
    "        scores = cross_validate(self.model, self.features, self.labels,scoring=scoring)\n",
    "        \n",
    "        cols = ['recall','recall_micro','precision_micro','d2_error']\n",
    "        cells = []\n",
    "        cells.append(round(scores['test_recall'].mean(),2))\n",
    "        cells.append(round(scores['test_recall_micro'].mean(),2))\n",
    "        \n",
    "        cells.append(round(scores['test_precision_micro'].mean(),2))\n",
    "        #cells.append(round(scores['test_f1_micro'].mean(),2))\n",
    "        cells.append(round(scores['test_d2_absolute_error_score'].mean(),2))\n",
    "\n",
    "        return cols, cells\n",
    "\n",
    "\n",
    "    def get_test_metrics(self):\n",
    "        pred = self.test_model.decision_function(self.features_test)\n",
    "        cols = ['recall','recall_micro','precision','d2_error']\n",
    "        cells = []\n",
    "        cells.append(round(recall_score(self.labels_test, self.predictions),3))\n",
    "        cells.append(round(recall_score(self.labels_test, self.predictions,average='micro'),3))\n",
    "       # cells.append(round(accuracy_score(self.labels_test, self.predictions),3))\n",
    "        cells.append(round(precision_score(self.labels_test, self.predictions,average='micro'),3))\n",
    "        cells.append(round(d2_absolute_error_score(self.labels_test,self.predictions),3))\n",
    "        \n",
    "        return cols, cells\n",
    "    \n",
    "    def show_train_metrics(self):\n",
    "        \n",
    "        cols, cell_text = self.get_train_metrics()\n",
    "        rows = [\"Train Results\"]\n",
    "        fig,axs = plt.subplots(figsize=(3,2))\n",
    "        fig.suptitle(\"Model Performance\")\n",
    "        fig.canvas.header_visible = False\n",
    "        fig.patch.set_visible(False)\n",
    "        axs.axis('off')\n",
    "        axs.axis('tight')\n",
    "        \n",
    "        table = axs.table( colLabels=cols,rowLabels=rows,cellText=[cell_text],loc='center')\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(8)\n",
    "        table.scale(2,2)\n",
    "        plt.close()\n",
    "        return fig\n",
    "\n",
    "    def show_test_metrics(self):\n",
    "        cols , train_row = self.get_train_metrics()\n",
    "        _, test_row = self.get_test_metrics()\n",
    "        \n",
    "        \n",
    "        rows = [\"Training\",\"Testing\"]\n",
    "        fig,axs = plt.subplots(figsize=(3,2))\n",
    "        fig.suptitle(\"Model Performance\")\n",
    "        fig.canvas.header_visible = False\n",
    "        fig.patch.set_visible(False)\n",
    "        axs.axis('off')\n",
    "        axs.axis('tight')\n",
    "        \n",
    "        table = axs.table( colLabels=cols,rowLabels=rows,cellText=[train_row, test_row],loc='center')\n",
    "        table.auto_set_font_size(False)\n",
    "        table.set_fontsize(8)\n",
    "        table.scale(2,2)\n",
    "        plt.close()\n",
    "        return fig\n",
    "\n",
    "\n",
    "\n",
    "# populate the training results records\n",
    "tr = TrainingViewer(gr,feature_train, label_train,feature_test,label_test)\n",
    "tr.fit_model_with_record(0)\n",
    "# prevent plot from displpaying automatically\n",
    "plt.ioff() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No such comm: a17d10221e65417e9aa6ffbb7fd75b15\n",
      "No such comm: a17d10221e65417e9aa6ffbb7fd75b15\n",
      "No such comm: a17d10221e65417e9aa6ffbb7fd75b15\n",
      "No such comm: a17d10221e65417e9aa6ffbb7fd75b15\n",
      "No such comm: a17d10221e65417e9aa6ffbb7fd75b15\n",
      "No such comm: a17d10221e65417e9aa6ffbb7fd75b15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No such comm: eabbaa8ba039435fb0cb3bc46fabeb83\n",
      "No such comm: eabbaa8ba039435fb0cb3bc46fabeb83\n",
      "No such comm: eabbaa8ba039435fb0cb3bc46fabeb83\n",
      "No such comm: eabbaa8ba039435fb0cb3bc46fabeb83\n",
      "No such comm: eabbaa8ba039435fb0cb3bc46fabeb83\n",
      "No such comm: eabbaa8ba039435fb0cb3bc46fabeb83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No such comm: 1936d6a5a0554a80a908b64ee6b6d340\n",
      "No such comm: 3ca8139a3b404b148b8b6957c4270a04\n",
      "No such comm: 3ca8139a3b404b148b8b6957c4270a04\n",
      "No such comm: 3ca8139a3b404b148b8b6957c4270a04\n",
      "No such comm: 3ca8139a3b404b148b8b6957c4270a04\n",
      "No such comm: 3ca8139a3b404b148b8b6957c4270a04\n",
      "No such comm: 3ca8139a3b404b148b8b6957c4270a04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No such comm: ff2336287fdd475b92d6baa4a80ce432\n",
      "No such comm: ff2336287fdd475b92d6baa4a80ce432\n",
      "No such comm: ff2336287fdd475b92d6baa4a80ce432\n",
      "No such comm: ff2336287fdd475b92d6baa4a80ce432\n",
      "No such comm: ff2336287fdd475b92d6baa4a80ce432\n",
      "No such comm: ff2336287fdd475b92d6baa4a80ce432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No such comm: 9e6dabf498814bbab3c8528086989046\n",
      "No such comm: 9e6dabf498814bbab3c8528086989046\n",
      "No such comm: 9e6dabf498814bbab3c8528086989046\n",
      "No such comm: 9e6dabf498814bbab3c8528086989046\n",
      "No such comm: 9e6dabf498814bbab3c8528086989046\n",
      "No such comm: 9e6dabf498814bbab3c8528086989046\n",
      "No such comm: 4ba960e663d941f8b9ae3053be1396bc\n",
      "No such comm: 4ba960e663d941f8b9ae3053be1396bc\n",
      "No such comm: 4ba960e663d941f8b9ae3053be1396bc\n",
      "No such comm: 4ba960e663d941f8b9ae3053be1396bc\n",
      "No such comm: 4ba960e663d941f8b9ae3053be1396bc\n",
      "No such comm: 4ba960e663d941f8b9ae3053be1396bc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No such comm: 90569adeedba4bb28a8fd002101cca1b\n",
      "No such comm: 90569adeedba4bb28a8fd002101cca1b\n",
      "No such comm: 90569adeedba4bb28a8fd002101cca1b\n",
      "No such comm: 90569adeedba4bb28a8fd002101cca1b\n",
      "No such comm: 90569adeedba4bb28a8fd002101cca1b\n",
      "No such comm: 90569adeedba4bb28a8fd002101cca1b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No such comm: b99f52e794714b07996f7a405889521d\n",
      "No such comm: b99f52e794714b07996f7a405889521d\n",
      "No such comm: b99f52e794714b07996f7a405889521d\n",
      "No such comm: b99f52e794714b07996f7a405889521d\n",
      "No such comm: b99f52e794714b07996f7a405889521d\n",
      "No such comm: b99f52e794714b07996f7a405889521d\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rec_sel_label = widgets.Label(value=\"Select Record to View\")\n",
    "\n",
    "rec_sel_dropdown = widgets.Dropdown(\n",
    "    options=['1','2','3','4','5'],\n",
    "    value='1',\n",
    "    description='',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "# Handlers\n",
    "params_out = widgets.Output()\n",
    "record_out = widgets.Output()\n",
    "roc_out = widgets.Output()\n",
    "det_out = widgets.Output()\n",
    "stats_out =  widgets.Output()\n",
    "cm_out = widgets.Output()\n",
    "bxp_out = widgets.Output()\n",
    "prec_recall_out = widgets.Output()\n",
    "test_metrics_out = widgets.Output()\n",
    "\n",
    "run_oos_button  = widgets.Button(description='Test model on out of sample data')\n",
    "\n",
    "record_box = widgets.VBox([params_out,rec_sel_label,rec_sel_dropdown,record_out,prec_recall_out])\n",
    "\n",
    "model_box = widgets.VBox([test_metrics_out,prec_recall_out])\n",
    "stat_box = widgets.VBox([stats_out,bxp_out,cm_out,run_oos_button])\n",
    "chart_box = widgets.VBox([roc_out, det_out])\n",
    "left_box = record_box\n",
    "\n",
    "\n",
    "def initialize():\n",
    "    \n",
    "    with params_out:\n",
    "        params_out.clear_output()\n",
    "        display(tr.show_curr_record_params())\n",
    "\n",
    "    with record_out:\n",
    "\n",
    "        record_out.clear_output()\n",
    "        display(tr.print_records_to_table())\n",
    "\n",
    "    with stats_out:\n",
    "        stats_out.clear_output()\n",
    "        display(tr.show_train_metrics())\n",
    "\n",
    "    with cm_out:\n",
    "        cm_out.clear_output()\n",
    "        display(tr.show_confusion_matrix_train())\n",
    "\n",
    "    with roc_out:\n",
    "        roc_out.clear_output()\n",
    "        display(tr.show_ROC())\n",
    "\n",
    "    with det_out:\n",
    "        det_out.clear_output()\n",
    "        display(tr.show_DET())\n",
    "\n",
    "    with bxp_out:\n",
    "        bxp_out.clear_output()\n",
    "        display(tr.show_box_plot())\n",
    "\n",
    "    with prec_recall_out:\n",
    "        prec_recall_out.clear_output()\n",
    "        display(tr.show_precision_recall())\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# observers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2a08d87915461e85e33e8fd97c4bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Output(), Label(value='Select Record to View'), Dropdown(options=('1', '2', '3',â€¦"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def select_record_to_view(dfx,names):\n",
    "    left_box = record_box\n",
    "    val = int(names.new) - 1\n",
    "    dfx.select_record(val)\n",
    "  \n",
    "    with params_out:\n",
    "        params_out.clear_output()\n",
    "        display(tr.show_curr_record_params())\n",
    "    \n",
    "    with stats_out:\n",
    "        stats_out.clear_output()\n",
    "        display(dfx.show_train_metrics())\n",
    "\n",
    "    with cm_out:\n",
    "        cm_out.clear_output()\n",
    "        display(dfx.show_confusion_matrix_train())\n",
    "\n",
    "    with roc_out:\n",
    "        roc_out.clear_output()\n",
    "        display(dfx.show_ROC())\n",
    "\n",
    "    with det_out:\n",
    "        det_out.clear_output()\n",
    "        display(dfx.show_DET())\n",
    "\n",
    "    with prec_recall_out:\n",
    "        prec_recall_out.clear_output()\n",
    "        display(dfx.show_precision_recall())\n",
    "\n",
    "    plt.close('all')\n",
    "    \n",
    "\n",
    "def test_model_on_oos(dfx,val):\n",
    "    \n",
    "    dfx.set_testing_model()\n",
    "    with params_out:\n",
    "        params_out.clear_output()\n",
    "        display(tr.show_curr_record_params())\n",
    "\n",
    "    with cm_out:\n",
    "        cm_out.clear_output()\n",
    "        display(dfx.show_confusion_matrix_train())\n",
    "\n",
    "    with roc_out:\n",
    "        roc_out.clear_output()\n",
    "        display(dfx.show_ROC())\n",
    "\n",
    "    with det_out:\n",
    "        det_out.clear_output()\n",
    "        display(dfx.show_DET())\n",
    "    \n",
    "    with prec_recall_out:\n",
    "        prec_recall_out.clear_output()\n",
    "        display(dfx.show_precision_recall())\n",
    "    \n",
    "    with bxp_out:\n",
    "        bxp_out.clear_output()\n",
    "        display(dfx.show_confusion_matrix_test())\n",
    "\n",
    "    with record_out:\n",
    "        record_out.clear_output() \n",
    "        display(dfx.show_test_metrics())\n",
    "        \n",
    "\n",
    "    with test_metrics_out:\n",
    "        test_metrics_out.clear_output()\n",
    "        \n",
    "\n",
    "\n",
    "    plt.close('all')     \n",
    "\n",
    "\n",
    "initialize()\n",
    "\n",
    "\n",
    "\n",
    "rec_sel_dropdown.observe(partial(select_record_to_view,tr),names='value')\n",
    "run_oos_button.on_click(partial(test_model_on_oos, tr))\n",
    "\n",
    "gridsearch_panel = widgets.HBox([left_box, stat_box,chart_box])\n",
    "\n",
    "gridsearch_panel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tr.test_mode = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
